[
  {
    "objectID": "lab-01.html",
    "href": "lab-01.html",
    "title": "lab-01",
    "section": "",
    "text": "read in the data from the NY-Times URL\n\n\ndata &lt;- read_csv(\"https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv\")\n\n\ncreate an object called my.date and set it as “2022-02-01”\ncreate an object called my.state and set it to “Colorado”\n\n\nmy.date &lt;- as.Date(\"2022-02-01\")\nmy.state &lt;- \"Colorado\"\n\n\nmake a subset that limits the data to Colorado and add a new column with daily new cases. do the same for new deaths\n\n\nco_data &lt;- data %&gt;%\n  filter(state == my.state) %&gt;%\n  group_by(county) %&gt;%\n  mutate(new_cases = cases - lag(cases, n = 1),\n         new_deaths = deaths - lag(deaths)) %&gt;%\n  drop_na() %&gt;%\n  ungroup()\n\n\ngenerate 2 tables. the first should show the 5 counties with the most cummulative cases on your date of interest, and the second should show the 5 counties with the most new cases on that same date\n\n\ntoday_data &lt;- filter(co_data, date == my.date)\n\nslice_max(today_data, n = 5, order_by = cases) %&gt;%\n  select(county, state, cases) %&gt;%\n  flextable() %&gt;%\n  set_header_labels(\n    cases = \"cases\") %&gt;%\n  set_caption(\"Top 5 Counties by Cummulative COVID-19 Cases\")\n\ncountystatecasesEl PasoColorado170,673DenverColorado159,022ArapahoeColorado144,255AdamsColorado126,768JeffersonColorado113,240\n\nslice_max(today_data, n = 5, order_by = new_cases) %&gt;%\n  select(county, state, new_cases) %&gt;%\n  flextable() %&gt;%\n  set_header_labels(\n    new_cases = \"cases\") %&gt;%\n  set_caption(\"Top 5 Counties by New COVID-19 Cases\")\n\ncountystatecasesEl PasoColorado630ArapahoeColorado401DenverColorado389AdamsColorado326JeffersonColorado291"
  },
  {
    "objectID": "lab-01.html#question-1.-daily-summary",
    "href": "lab-01.html#question-1.-daily-summary",
    "title": "lab-01",
    "section": "",
    "text": "read in the data from the NY-Times URL\n\n\ndata &lt;- read_csv(\"https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv\")\n\n\ncreate an object called my.date and set it as “2022-02-01”\ncreate an object called my.state and set it to “Colorado”\n\n\nmy.date &lt;- as.Date(\"2022-02-01\")\nmy.state &lt;- \"Colorado\"\n\n\nmake a subset that limits the data to Colorado and add a new column with daily new cases. do the same for new deaths\n\n\nco_data &lt;- data %&gt;%\n  filter(state == my.state) %&gt;%\n  group_by(county) %&gt;%\n  mutate(new_cases = cases - lag(cases, n = 1),\n         new_deaths = deaths - lag(deaths)) %&gt;%\n  drop_na() %&gt;%\n  ungroup()\n\n\ngenerate 2 tables. the first should show the 5 counties with the most cummulative cases on your date of interest, and the second should show the 5 counties with the most new cases on that same date\n\n\ntoday_data &lt;- filter(co_data, date == my.date)\n\nslice_max(today_data, n = 5, order_by = cases) %&gt;%\n  select(county, state, cases) %&gt;%\n  flextable() %&gt;%\n  set_header_labels(\n    cases = \"cases\") %&gt;%\n  set_caption(\"Top 5 Counties by Cummulative COVID-19 Cases\")\n\ncountystatecasesEl PasoColorado170,673DenverColorado159,022ArapahoeColorado144,255AdamsColorado126,768JeffersonColorado113,240\n\nslice_max(today_data, n = 5, order_by = new_cases) %&gt;%\n  select(county, state, new_cases) %&gt;%\n  flextable() %&gt;%\n  set_header_labels(\n    new_cases = \"cases\") %&gt;%\n  set_caption(\"Top 5 Counties by New COVID-19 Cases\")\n\ncountystatecasesEl PasoColorado630ArapahoeColorado401DenverColorado389AdamsColorado326JeffersonColorado291"
  },
  {
    "objectID": "lab-01.html#question-2.-evaluating-census-data-eda",
    "href": "lab-01.html#question-2.-evaluating-census-data-eda",
    "title": "lab-01",
    "section": "Question 2. Evaluating Census Data (EDA)",
    "text": "Question 2. Evaluating Census Data (EDA)\n\nread in the population data and create a five digit FIP variable. keep only columns that contain “NAME” or “2021” and remove all state level rows\n\n\n# Load population data from the given URL\npop_url &lt;- read_csv(\"co-est2023-alldata.csv\")\n\n\n# Read and process the population data\ncd &lt;- pop_url %&gt;%\n  filter(COUNTY != \"000\") %&gt;%               # Filter out rows with COUNTY = \"000\"\n  mutate(fips = paste0(STATE, COUNTY)) %&gt;%   # Create a new FIPS code column\n  select(STNAME, COUNTY, fips, contains(\"2021\"))  # Select relevant columns\n\n\nb. Data Exploration: Attributes are state names and numbers. I am able to see that there are columns for state, county, fips, population, births, and deaths. Fips matches one of the columns in the Covid data. The dimensions have been modified to include counties that do not have the identification number “000”, and includes columns that have information for the year 2021."
  },
  {
    "objectID": "lab-01.html#question-3-per-capita-summary",
    "href": "lab-01.html#question-3-per-capita-summary",
    "title": "lab-01",
    "section": "Question 3: Per Capita Summary",
    "text": "Question 3: Per Capita Summary\n\njoin the population data to the Colorado COVID data and compute the per capita cumulative cases, per capita new cases, and per capita new deaths. generate 2 new tables. the first should show the 5 counties with the most cumulative cases per capita on your date, and the second should show the 5 counties with the most new cases per capita on the same date\n\n\nco_join &lt;- inner_join(co_data, cd, by = \"fips\") \n\n\nper_capita &lt;- co_join %&gt;%\n  group_by(county) %&gt;%\n  mutate(cases_per_capita = (cases/POPESTIMATE2021) * 100000,\n         new_cases_per_capita = (new_cases/POPESTIMATE2021) * 100000,\n         new_deaths_per_capita = (deaths/POPESTIMATE2021) * 100000) %&gt;%\n  drop_na() %&gt;%\n  ungroup() \n  \ncapita_my_date &lt;- per_capita %&gt;%\n  filter(date == my.date)\n\nslice_max(capita_my_date, n = 5, order_by = cases_per_capita) %&gt;%\n  select(county, cases_per_capita) %&gt;%\n  flextable() %&gt;%\n  set_header_labels(\n    cases_per_capita = \"cases per capita\") %&gt;%\n  set_caption(\"Top 5 Colorado Counties\")\n\ncountycases per capitaCrowley51,176.98Bent41,187.49Pitkin34,296.59Lincoln34,240.82Logan30,477.01\n\nslice_max(capita_my_date, n = 5, order_by = new_cases_per_capita) %&gt;%\n  select(county, new_cases_per_capita) %&gt;%\n  flextable() %&gt;%\n  set_header_labels(\n    new_cases_per_capita = \"new cases per capita\") %&gt;%\n  set_caption(\"Top 5 Colorado Counties by New Cases\")\n\ncountynew cases per capitaCrowley976.4603Bent412.0622Sedgwick386.9304Washington287.5924Las Animas265.1039"
  },
  {
    "objectID": "lab-01.html#question-4-rolling-thresholds",
    "href": "lab-01.html#question-4-rolling-thresholds",
    "title": "lab-01",
    "section": "Question 4: Rolling Thresholds",
    "text": "Question 4: Rolling Thresholds\n\nfilter the merged COVID/Population data for Colorado to include the last 14 days. determine the total number of new cases in the last 14 days per 100,000 people. print a table of the top 5 counties and report the number of counties that meet the watch list condition\n\n\nthreshold &lt;- per_capita %&gt;%\n  filter(date &gt;= (my.date - 14) & date &lt;= my.date) %&gt;%  \n  group_by(county) %&gt;%\n  summarize(\n    total_new_cases = sum(new_cases),  \n    population = sum(POPESTIMATE2021)) %&gt;%\n  mutate(new_cases_threshold = (total_new_cases / population) * 100000) %&gt;%  \n  drop_na() %&gt;%\n  ungroup()\n\nslice_max(threshold, n = 5, order_by = new_cases_threshold) %&gt;%\n  select(county, new_cases_threshold) %&gt;%\n  flextable() %&gt;%\n  set_header_labels(new_cases_threshold = \"new cases\") %&gt;%\n  set_caption(\"Top 5 Colorado Watch List Counties\")\n\ncountynew casesCrowley365.0102Lincoln250.9288Alamosa250.5177Mineral222.4614Conejos222.4567\n\nthreshold %&gt;%\n  filter(new_cases_threshold &gt; 100) %&gt;%\n  nrow()\n\n[1] 53\n\n\n\n53 Colorado counties meet the watch list condition"
  },
  {
    "objectID": "lab-01.html#question-5-death-toll",
    "href": "lab-01.html#question-5-death-toll",
    "title": "lab-01",
    "section": "Question 5: Death toll",
    "text": "Question 5: Death toll\n\ndetermine the percentage of deaths in each county that were attributed to COVID last year(2021). plot a visualization of all counties where COVID deaths account for 20% or more of the annual death toll\n\n\ndeath_toll_2021 &lt;- co_join %&gt;%\n  mutate(year = year(date)) %&gt;%\n  filter(year == 2021) %&gt;%\n  group_by(county) %&gt;%\n  summarize(covid_death = sum(new_deaths),\n            total_deaths = first(DEATHS2021)) %&gt;% \n  mutate(death_toll = covid_death / total_deaths * 100)\n\ndeath_20 &lt;- death_toll_2021 %&gt;%\n  filter(death_toll &gt; 20)\n\ndeath_20 %&gt;%\n  ggplot(aes(x = death_toll, y = reorder(county, death_toll))) + \n  geom_point(size = 3, color = \"#1B9E77\") +  # Use the first color from Set2\n  labs(x = \"death toll (%)\", \n       y = \"county\",\n       caption = \"Colorado counties where COVID-19 accounted for more than 20% of total deaths in 2021\") +\n  theme_minimal() +\n  theme(legend.position = \"none\",\n        plot.caption = element_text(hjust = 0))"
  },
  {
    "objectID": "lab-01.html#question-6-multi-state",
    "href": "lab-01.html#question-6-multi-state",
    "title": "lab-01",
    "section": "Question 6: Multi-state",
    "text": "Question 6: Multi-state\n\ngroup/summarize county level data to the state level, filter it to the four states of interest, and calculate the number of daily new cases and the 7-day rolling mean\n\n\nstate_data &lt;- data %&gt;%\n  filter(state %in% c(\"Alabama\", \"Ohio\", \"Colorado\", \"New York\")) %&gt;%\n  group_by(state, date) %&gt;%\n  summarize(fips = first(fips),\n            cases = sum(cases, na.rm = TRUE), \n            deaths = sum(deaths, na.rm = TRUE), \n            .groups = \"drop\") %&gt;%  \n  group_by(state) %&gt;%  \n  arrange(state, date) %&gt;%  \n  mutate(new_cases = pmax(0, cases - lag(cases, n = 1)),  \n         new_deaths = pmax(0, deaths - lag(deaths, n = 1)),\n         new_cases_mean = rollmean(new_cases, 7, fill = NA, align = \"right\"),\n         new_deaths_mean = rollmean(new_deaths, 7, fill = NA, align = \"right\")) %&gt;%\n  drop_na() %&gt;%  \n  ungroup()  \n\n\nfacet plot the daily new cases and the 7-day rolling mean\n\n\nggplot(state_data, aes(x = date, y = new_cases)) +  \n  geom_col(aes(fill = state)) +  \n  facet_wrap(~state, scales = \"free_y\") +  \n  labs(title = \"Daily New COVID-19 Cases\",\n       x = \"date\", \n       y = \"new cases\") +\n  scale_fill_brewer(palette = \"Set2\") +  \n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\nggplot(state_data, aes(x = date, y = new_cases_mean)) +  \n  geom_col(aes(fill = state)) +  \n  facet_wrap(~state, scales = \"free_y\") +  \n  labs(title = \"COVID-19 Cases 7-Day Rolling Mean\",\n       x = \"date\", \n       y = \"new cases\") +\n  scale_fill_brewer(palette = \"Set2\") +  \n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nexplore the cases per capita of each state and calculate the 7-day rolling mean of the new cases per capita\n\n\nstates_join &lt;- inner_join(state_data, cd, by = \"fips\") %&gt;%\n  mutate(new_cases_capita = new_cases / POPESTIMATE2021,  \n         new_cases_mean = rollmean(new_cases_capita, 7, fill = NA, align = \"right\")) %&gt;%\n  mutate(state = factor(state, levels = c(\"Alabama\", \"Ohio\", \"Colorado\", \"New York\"))) \n\n\nplot the 7-day rolling averages overlying each other\n\n\nggplot(states_join, aes(x = date, y = new_cases_mean, fill = state, group = state)) +  \n  geom_col() +  \n  labs(title = \"7-Day Rolling Average of New COVID-19 Cases Per Capita\",\n       x = \"date\", \n       y = \"rolling average\") +\n  scale_fill_brewer(palette = \"Set2\") +  \n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))  \n\n\n\n\n\n\n\n\n\nBriefly describe the influence scaling by population had on the analysis? Does it make some states look better? Some worse? How so?\n\n\nScaling by population shows that per capita rolling averages are higher in Alabama and Ohio. This differs from the state wide daily cases and 7-day rolling averages, which showed New York as the state with the highest COVID-19 cases."
  },
  {
    "objectID": "lab-01.html#question-7.-time-and-space",
    "href": "lab-01.html#question-7.-time-and-space",
    "title": "lab-01",
    "section": "Question 7. Time and Space",
    "text": "Question 7. Time and Space\n\ncalculate the Weighted Mean Center of the COVID-19 outbreak\n\n\ncounty_centroids &lt;- readr::read_csv('https://raw.githubusercontent.com/mikejohnson51/csu-ess-330/refs/heads/main/resources/county-centroids.csv')\n\n\ncounty_join &lt;- inner_join(county_centroids, data, by = \"fips\") %&gt;%\n  group_by(date) %&gt;%  \n  summarise(\n    weighted_x_cases = sum(LON * cases, na.rm = TRUE) / sum(cases, na.rm = TRUE),\n    weighted_y_cases = sum(LAT * cases, na.rm = TRUE) / sum(cases, na.rm = TRUE),\n    weighted_x_deaths = sum(LON * deaths, na.rm = TRUE) / sum(deaths, na.rm = TRUE),\n    weighted_y_deaths = sum(LAT * deaths, na.rm = TRUE) / sum(deaths, na.rm = TRUE),\n    cases = sum(cases, na.rm = TRUE),\n    deaths = sum(deaths, na.rm = TRUE)\n  ) %&gt;%\n  drop_na() \n\n\nmake two plots next to each other showing cases in navy and deaths in red. describe the differences in the plots and what they mean about the spatial patterns seen with COVID impacts\n\n\na &lt;- ggplot() +\n  borders(\"state\", fill = \"gray90\", colour = \"white\") +\n  geom_point(data = county_join, aes(x = weighted_x_cases, y = weighted_y_cases, size = cases), color = \"#377EB8\") +\n  labs(title = \"COVID-19 Cases\") +\n  theme_minimal() +  \n  theme(\n    axis.title = element_blank(), \n    axis.text = element_blank(),   \n    axis.ticks = element_blank(),  \n    panel.grid = element_blank()   \n  )\n\nb &lt;- ggplot() +\n  borders(\"state\", fill = \"gray90\", colour = \"white\") +\n  geom_point(data = county_join, aes(x = weighted_x_deaths, y = weighted_y_deaths, size=deaths), color = \"#E41A1C\") +\n  labs(title = \"COVID-19 Deaths\") +\n  theme_minimal() +\n  theme(\n    axis.title = element_blank(),  \n    axis.text = element_blank(),   \n    axis.ticks = element_blank(),  \n    panel.grid = element_blank()   \n  )\n\na + b\n\n\n\n\n\n\n\n\n\nThe weighted mean of both COVID cases and Deaths are highest around Arkansaw, Missouri, Tenessee, Kentucky, and Illinois. Weighted Cases appear to be highest in middle North America, whereas death spread towards the Pacific Northwest. There are higher numbers of cases than deaths."
  },
  {
    "objectID": "lab-01.html#question-8-trends",
    "href": "lab-01.html#question-8-trends",
    "title": "lab-01",
    "section": "Question 8: Trends",
    "text": "Question 8: Trends\n\nData Visualization\n\ncompute county level daily new cases and deaths, and then join it to the census data\nadd a new column to the data for year, month, and season\ngroup the data by state, year, and season and summarize the total population, new cases, and new deaths per grouping\napply a log transformation to cases, deaths, and population\n\n\ntrends &lt;- data %&gt;%\n  group_by(fips) %&gt;%\n  mutate(new_cases = pmax(0, cases - lag(cases, n = 1)),\n         new_deaths = pmax(0, deaths - lag(deaths))) %&gt;%\n  ungroup() %&gt;%\n  left_join(cd, by = \"fips\") %&gt;%\n  mutate(year = lubridate::year(date),\n         month = lubridate::month(date),\n         season = dplyr::case_when(\n           month %in% 3:5 ~ \"Spring\",    \n           month %in% 6:8 ~ \"Summer\",    \n           month %in% 9:11 ~ \"Fall\",     \n           month %in% c(12, 1, 2) ~ \"Winter\")) %&gt;%\n  group_by(state, year, season) %&gt;%\n  summarize(\n    population = sum(POPESTIMATE2021),   \n    new_cases = sum(new_cases, na.rm = TRUE),\n    new_deaths = sum(new_deaths, na.rm = TRUE)) %&gt;%\n  ungroup() %&gt;%\n  mutate(log_cases = log(new_cases + 1),          \n         log_deaths = log(new_deaths + 1),       \n         log_population = log(population))\n\n\n\nModel Building\n\nbuild a linear model to predict the log of cases using the log of deaths, the log of population, and the season.\nOnce the model is built, summarize it (summary) and report the R-squared value and the p-value of the model. What does this mean for the value of its application?\n\n\nlm_model &lt;- lm(log_cases ~ log_deaths*log_population + season, data = trends)\n\nsummary(lm_model)\n\n\nCall:\nlm(formula = log_cases ~ log_deaths * log_population + season, \n    data = trends)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.31412 -0.31982 -0.02291  0.34272  1.37613 \n\nCoefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)               -2.69871    3.21708  -0.839  0.40274    \nlog_deaths                 0.77857    0.39852   1.954  0.05242 .  \nlog_population             0.53675    0.18023   2.978  0.00333 ** \nseasonSpring              -0.79528    0.12221  -6.507 8.55e-10 ***\nseasonSummer              -0.31156    0.13100  -2.378  0.01852 *  \nseasonWinter               0.37357    0.11530   3.240  0.00144 ** \nlog_deaths:log_population -0.01318    0.02103  -0.627  0.53161    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4979 on 167 degrees of freedom\n  (380 observations deleted due to missingness)\nMultiple R-squared:  0.8764,    Adjusted R-squared:  0.8719 \nF-statistic: 197.3 on 6 and 167 DF,  p-value: &lt; 2.2e-16\n\n\n\nMultiple R-squared: 0.8764, Adjusted R-squared: 0.8719, p-value: &lt; 2.2e-16\n\n\nThe R-squared value is high, indicating a strong model fit. The p-value is low, indicating that the model is statistically significant."
  },
  {
    "objectID": "lab-01.html#question-9-evaluation",
    "href": "lab-01.html#question-9-evaluation",
    "title": "lab-01",
    "section": "Question 9: Evaluation",
    "text": "Question 9: Evaluation\n\ngenerate a data frame of predictions and residuals\ncreate a scatter plot of predicted cases vs. actual cases. add a line of best fit to the plot, and make the plot as appealing as possible. Describe the relationship that you see…are you happy with the model?\n\n\nYes, I am happy with the model. The scatter plot shows a strong linear relationship between predicted and actual log cases, with the points following the line of best fit.\n\ncreate a histogram of the residuals to visually check for residual normality. how does the distribution look? was a linear model appropriate for this case?\n\n\n\nThe histogram looks to be normally distributed. A linear model was appropriate for this case.\n\nmodel_eval &lt;- broom::augment(lm_model, trends = trends)\n\nggplot(model_eval, aes(x = log_cases, y = .fitted)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", color = \"#1B9E77\") +\n  labs(title = \"Predicted vs Actual Cases\",\n       x = \"actual\",     \n       y = \"predicted\") + \n  theme_minimal()\n\n\n\n\n\n\n\nggplot(model_eval, aes(x = .resid)) +\n  geom_histogram(fill = \"#1B9E77\", color = \"black\", bins = 30) +  \n  labs(title = \"Histogram of Residuals\",\n       x = \"residuals\") +  \n  theme_minimal()"
  }
]